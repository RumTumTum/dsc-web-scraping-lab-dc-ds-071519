{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen a more extensive example of developing a web scraping script, it's time to further practice and formalize that knowledge by writing functions to parse specific pieces of information from the web page and then synthesizing these into a larger loop that will iterate over successive web pages in order to build a complete dataset.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Write functions to parse specific information from a web page\n",
    "* Iterate over successive web pages in order to create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Overview\n",
    "\n",
    "This lab will build upon the previous lesson. In the end, you'll look to write a script that will iterate over all of the pages for the demo site and extract the title, price, star rating and availability of each book listed. Building up to that, you'll formalize the concepts from the lesson by writing functions that will extract a list of each of these features for each web page. You'll then combine these functions into the full script which will look something like this:  \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame()\n",
    "for i in range(2,51):\n",
    "    url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(i)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    new_titles = retrieve_titles(soup)\n",
    "    new_star_ratings = retrieve_ratings(soup)\n",
    "    new_prices = retrieve_prices(soup)\n",
    "    new_avails = retrieve_avails(soup)\n",
    "    ...\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "site_download = requests.get(url)\n",
    "# site_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(site_download.content)\n",
    "pods = soup.select('article', class_=\"product_pod\")\n",
    "# pods[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Â£51.77'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(soup.select('.product_pod .price_color')[0].prettify())\n",
    "soup.select('.product_pod .price_color')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.select('.product_pod')[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    \\n        In stock\\n    \\n'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.select('.product_pod p')[0]['class'][1]\n",
    "soup.select('.product_pod .instock.availability')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://books.toscrape.com/catalogue/page-51.html\"\n",
    "site_download = requests.get(url)\n",
    "site_download.status_code\n",
    "# soup = BeautifulSoup(site_download.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Page Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_data(soup):\n",
    "    str_to_int = {'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "    title_list = [link['title'] for link in soup.select('.product_pod h3 a')]\n",
    "    price_list = [float(link.text[1:]) for link in soup.select('.product_pod .price_color')]\n",
    "    star_list_str = [link['class'][1] for link in soup.select('.product_pod .star-rating')]\n",
    "    star_list = list(map(lambda x: str_to_int[x],star_list_str))\n",
    "    avail_list_str = [link.text for link in soup.select('.product_pod .instock.availability')]\n",
    "    avail_list = list(map(lambda x: 1 if x.find('In stock') >0 else 0,avail_list_str))\n",
    "    df_of_page = pd.DataFrame({'title':title_list,'price_gbp':price_list,'rating_stars':star_list,'availability':avail_list})\n",
    "    return df_of_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Page Data (all pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading page http://books.toscrape.com/catalogue/page-49.html\n",
      "downloading page http://books.toscrape.com/catalogue/page-50.html\n"
     ]
    }
   ],
   "source": [
    "list_of_pages = []\n",
    "for x in range(49,55):\n",
    "    try:\n",
    "        url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(x)\n",
    "        site_download = requests.get(url)\n",
    "        assert(site_download.status_code == 200),\"page load error\"\n",
    "        soup = BeautifulSoup(site_download.content)\n",
    "        list_of_pages.append(retrieve_all_data(soup))\n",
    "        print(\"downloading page {}\".format(url))\n",
    "    except:\n",
    "        break\n",
    "all_pages = pd.concat(list_of_pages)\n",
    "all_pages.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price_gbp</th>\n",
       "      <th>rating_stars</th>\n",
       "      <th>availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the Road (Duluoz Legend)</td>\n",
       "      <td>32.36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Old Records Never Die: One Man's Quest for His...</td>\n",
       "      <td>55.66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off Sides (Off #1)</td>\n",
       "      <td>39.45</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Of Mice and Men</td>\n",
       "      <td>47.11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Myriad (Prentor #1)</td>\n",
       "      <td>58.75</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>My Perfect Mistake (Over the Top #1)</td>\n",
       "      <td>38.92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ms. Marvel, Vol. 1: No Normal (Ms. Marvel (201...</td>\n",
       "      <td>39.39</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meditations</td>\n",
       "      <td>25.89</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Matilda</td>\n",
       "      <td>28.34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lost Among the Living</td>\n",
       "      <td>27.70</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lord of the Flies</td>\n",
       "      <td>24.89</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Listen to Me (Fusion #1)</td>\n",
       "      <td>58.99</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kitchens of the Great Midwest</td>\n",
       "      <td>57.20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>38.43</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Imperfect Harmony</td>\n",
       "      <td>34.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Icing (Aces Hockey #2)</td>\n",
       "      <td>40.44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hawkeye, Vol. 1: My Life as a Weapon (Hawkeye #1)</td>\n",
       "      <td>45.24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Having the Barbarian's Baby (Ice Planet Barbar...</td>\n",
       "      <td>34.96</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Giant Days, Vol. 1 (Giant Days #1-4)</td>\n",
       "      <td>56.76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fruits Basket, Vol. 1 (Fruits Basket #1)</td>\n",
       "      <td>40.28</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>38.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Forever Rockers (The Rocker #12)</td>\n",
       "      <td>28.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fighting Fate (Fighting #6)</td>\n",
       "      <td>39.24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Emma</td>\n",
       "      <td>32.93</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Eat, Pray, Love</td>\n",
       "      <td>51.32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Deep Under (Walker Security #1)</td>\n",
       "      <td>47.09</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Choosing Our Religion: The Spiritual Lives of ...</td>\n",
       "      <td>28.42</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Charlie and the Chocolate Factory (Charlie Buc...</td>\n",
       "      <td>22.85</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Charity's Cross (Charles Towne Belles #4)</td>\n",
       "      <td>41.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bright Lines</td>\n",
       "      <td>39.07</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bridget Jones's Diary (Bridget Jones #1)</td>\n",
       "      <td>29.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bounty (Colorado Mountain #7)</td>\n",
       "      <td>37.26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Blood Defense (Samantha Brinkman #1)</td>\n",
       "      <td>20.30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bleach, Vol. 1: Strawberry and the Soul Reaper...</td>\n",
       "      <td>34.65</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Beyond Good and Evil</td>\n",
       "      <td>43.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Alice in Wonderland (Alice's Adventures in Won...</td>\n",
       "      <td>55.53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)</td>\n",
       "      <td>57.06</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A Spy's Devotion (The Regency Spies of London #1)</td>\n",
       "      <td>16.97</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1st to Die (Women's Murder Club #1)</td>\n",
       "      <td>53.98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1,000 Places to See Before You Die</td>\n",
       "      <td>26.08</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  price_gbp  \\\n",
       "0                         On the Road (Duluoz Legend)      32.36   \n",
       "1   Old Records Never Die: One Man's Quest for His...      55.66   \n",
       "2                                  Off Sides (Off #1)      39.45   \n",
       "3                                     Of Mice and Men      47.11   \n",
       "4                                 Myriad (Prentor #1)      58.75   \n",
       "5                My Perfect Mistake (Over the Top #1)      38.92   \n",
       "6   Ms. Marvel, Vol. 1: No Normal (Ms. Marvel (201...      39.39   \n",
       "7                                         Meditations      25.89   \n",
       "8                                             Matilda      28.34   \n",
       "9                               Lost Among the Living      27.70   \n",
       "10                                  Lord of the Flies      24.89   \n",
       "11                           Listen to Me (Fusion #1)      58.99   \n",
       "12                      Kitchens of the Great Midwest      57.20   \n",
       "13                                          Jane Eyre      38.43   \n",
       "14                                  Imperfect Harmony      34.74   \n",
       "15                             Icing (Aces Hockey #2)      40.44   \n",
       "16  Hawkeye, Vol. 1: My Life as a Weapon (Hawkeye #1)      45.24   \n",
       "17  Having the Barbarian's Baby (Ice Planet Barbar...      34.96   \n",
       "18               Giant Days, Vol. 1 (Giant Days #1-4)      56.76   \n",
       "19           Fruits Basket, Vol. 1 (Fruits Basket #1)      40.28   \n",
       "20                                       Frankenstein      38.00   \n",
       "21                   Forever Rockers (The Rocker #12)      28.80   \n",
       "22                        Fighting Fate (Fighting #6)      39.24   \n",
       "23                                               Emma      32.93   \n",
       "24                                    Eat, Pray, Love      51.32   \n",
       "25                    Deep Under (Walker Security #1)      47.09   \n",
       "26  Choosing Our Religion: The Spiritual Lives of ...      28.42   \n",
       "27  Charlie and the Chocolate Factory (Charlie Buc...      22.85   \n",
       "28          Charity's Cross (Charles Towne Belles #4)      41.24   \n",
       "29                                       Bright Lines      39.07   \n",
       "30           Bridget Jones's Diary (Bridget Jones #1)      29.82   \n",
       "31                      Bounty (Colorado Mountain #7)      37.26   \n",
       "32               Blood Defense (Samantha Brinkman #1)      20.30   \n",
       "33  Bleach, Vol. 1: Strawberry and the Soul Reaper...      34.65   \n",
       "34                               Beyond Good and Evil      43.38   \n",
       "35  Alice in Wonderland (Alice's Adventures in Won...      55.53   \n",
       "36   Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)      57.06   \n",
       "37  A Spy's Devotion (The Regency Spies of London #1)      16.97   \n",
       "38                1st to Die (Women's Murder Club #1)      53.98   \n",
       "39                 1,000 Places to See Before You Die      26.08   \n",
       "\n",
       "    rating_stars  availability  \n",
       "0              3             1  \n",
       "1              2             1  \n",
       "2              5             1  \n",
       "3              2             1  \n",
       "4              4             1  \n",
       "5              2             1  \n",
       "6              4             1  \n",
       "7              2             1  \n",
       "8              1             1  \n",
       "9              4             1  \n",
       "10             3             1  \n",
       "11             3             1  \n",
       "12             5             1  \n",
       "13             5             1  \n",
       "14             4             1  \n",
       "15             4             1  \n",
       "16             3             1  \n",
       "17             4             1  \n",
       "18             4             1  \n",
       "19             5             1  \n",
       "20             2             1  \n",
       "21             3             1  \n",
       "22             3             1  \n",
       "23             2             1  \n",
       "24             3             1  \n",
       "25             5             1  \n",
       "26             4             1  \n",
       "27             3             1  \n",
       "28             1             1  \n",
       "29             5             1  \n",
       "30             1             1  \n",
       "31             4             1  \n",
       "32             3             1  \n",
       "33             5             1  \n",
       "34             1             1  \n",
       "35             1             1  \n",
       "36             4             1  \n",
       "37             5             1  \n",
       "38             1             1  \n",
       "39             5             1  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Up: Write a new version of the script you just wrote. \n",
    "\n",
    "If you used url hacking to generate each successive page url, instead write a function that retrieves the link from the `\"next\"` button at the bottom of the page. Conversely, if you already used this approach above, use URL-hacking (arguably the easier of the two methods in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! You just completed your first full web scraping project! You're ready to start harnessing the power of the web!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
